{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zdlFQu4v93e1"
      },
      "source": [
        "# Phase 1 - Ingestion and Cleaning\n",
        "\n",
        "In the Phase 2 of the Case Study, we will carry out the following steps:\n",
        "  - Ingest raw downloaded data\n",
        "  - Output a combined dataset ready for analysis and modeling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TO2Ll7aH93e5"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "from sys import platform\n",
        "import matplotlib.pyplot as plt\n",
        "import datetime\n",
        "import numpy as np\n",
        "import pickle\n",
        "import seaborn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "faWvI5DO93e6"
      },
      "outputs": [],
      "source": [
        "# A helper function that you'll be using while reading the raw files\n",
        "def is_integer(x):\n",
        "    '''\n",
        "    This function returns True if x is an integer, and False otherwise\n",
        "    '''\n",
        "    try:\n",
        "        return (int(x) == float(x))\n",
        "    except:\n",
        "        return False"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FwvuxSgX93e7"
      },
      "source": [
        "## Parameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jqaGptt093e7"
      },
      "outputs": [],
      "source": [
        "# Define the directories that contain the files downloaded\n",
        "dir_cs = os.getcwd() + '/2003_download' # path to the directory where all the *.csv.zip files are located\n",
        "\n",
        "# Define the output path for the pickle\n",
        "pickle_file = \"clean_data.pickle\" # path to save cleaned data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j1YTaVws93e7"
      },
      "outputs": [],
      "source": [
        "# Identify the columns we'll be keeping from the dataset\n",
        "\n",
        "# NOTE: added the variable 'last_pymnt_d' to cols_to_pick\n",
        "\n",
        "cols_to_pick = ['id','loan_amnt','funded_amnt','term','int_rate','grade','emp_length','home_ownership', \\\n",
        "                'annual_inc','verification_status','issue_d','loan_status','purpose','dti','delinq_2yrs', \\\n",
        "                'earliest_cr_line','open_acc','pub_rec','fico_range_high','fico_range_low','revol_bal', \\\n",
        "                'revol_util','total_pymnt','recoveries','last_pymnt_d'] # list of features to use for this study as indicated in the handout\n",
        "\n",
        "# Identify the type of each of these column based on your CS-Phase 1 response\n",
        "float_cols = ['loan_amnt','funded_amnt', 'annual_inc','dti','delinq_2yrs','open_acc','pub_rec','fico_range_high', \\\n",
        "              'fico_range_low','revol_bal','total_pymnt','recoveries']\n",
        "cat_cols = ['term','grade', 'emp_length','home_ownership','verification_status','loan_status', \\\n",
        "            'purpose'] # categorical features\n",
        "perc_cols = ['int_rate', 'revol_util']\n",
        "date_cols = ['issue_d', 'earliest_cr_line', 'last_pymnt_d']\n",
        "\n",
        "# Ensure that we have types for every column\n",
        "assert set(cols_to_pick) - set(float_cols)  - set(cat_cols) - set(perc_cols) - set(date_cols) == set([\"id\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hRjzJOag93e8"
      },
      "outputs": [],
      "source": [
        "# Some of the columns selected will not be used directly in the model,\n",
        "# but will be used to generate other features.\n",
        "#\n",
        "# Create variables specifying the features that will be used\n",
        "\n",
        "# All categorical columns other than \"loan_status\" will be used as\n",
        "# discrete features\n",
        "\n",
        "discrete_features = list(set(cat_cols) - set([\"loan_status\"]))\n",
        "\n",
        "# All numeric columns will be used as continuous features\n",
        "continuous_features = list(float_cols + perc_cols)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uJKrMP2U93e8"
      },
      "source": [
        "## Ingestion\n",
        "Ingest the data files from both sets, perform consistency checks, and prepare one single file for each set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "izC4iqXb93e9"
      },
      "outputs": [],
      "source": [
        "def ingest_files(directory):\n",
        "    '''\n",
        "    This function will ingest every file in the specified directory\n",
        "    into a pandas dataframe. It will return a dictionary containing\n",
        "    these dataframes, keyed by the file name.\n",
        "\n",
        "    We assume the directory contains files directly downloaded from\n",
        "    the link given in the handout, and *only* those files. Thus, we\n",
        "    assume the files are zipped (pd.read_csv can read zipped files)\n",
        "    and we assume the first line in each file needs to be skipped.\n",
        "\n",
        "    Note that each file will be read *without* formatting\n",
        "    '''\n",
        "\n",
        "    # If the directory has no trailing slash, add one\n",
        "    if directory[-1] != \"/\":\n",
        "        directory = directory + \"/\"\n",
        "\n",
        "    all_files = os.listdir(directory) # get list of all files from the directory\n",
        "    output = {}\n",
        "\n",
        "    print(\"Directory \" + directory + \" has \" + str(len(all_files)) + \" files:\")\n",
        "    for i in all_files:\n",
        "        print(\"    Reading file \" + i)\n",
        "        output[i] = pd.read_csv(directory + i, dtype = 'str', skiprows = 1) # read each with dtype='str' and skip_rows =1\n",
        "\n",
        "        # Some of the files have \"summary\" lines that, for example\n",
        "        # read \"Total number of loans number in Policy 1: .....\"\n",
        "        # To remove those lines, find any lines with non-integer IDs\n",
        "        # and remove them\n",
        "        invalid_rows = output[i][\"id\"].apply(is_integer) == False # mask rows that have non-integer IDs. Use is_integer method\n",
        "        if invalid_rows.sum() > 0:\n",
        "            print(\"Found \" + str(invalid_rows.sum()) + \" invalid rows which were removed\")\n",
        "            output[i] = output[i][invalid_rows == False] # keeping valid rows in dataframe\n",
        "\n",
        "    return output # return dictionary of dataframe"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 305
        },
        "id": "1byMdZYG93e9",
        "outputId": "241d01e5-c705-4dc9-c601-459386d66d72"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-5544ff0a544f>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Ingest the set of files we downloaded using the defined method \"ingest_files\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mfiles_cs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mingest_files\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdir_cs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# dictionary of (filename, dataframe) as (key, value)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-10-b3d1b1c76718>\u001b[0m in \u001b[0;36mingest_files\u001b[0;34m(directory)\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0mdirectory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdirectory\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"/\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m     \u001b[0mall_files\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirectory\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# get list of all files from the directory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m     \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/2003_download/'"
          ]
        }
      ],
      "source": [
        "# Ingest the set of files we downloaded using the defined method \"ingest_files\"\n",
        "files_cs = ingest_files(dir_cs) # dictionary of (filename, dataframe) as (key, value)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SBnglMNc93e-"
      },
      "source": [
        "### Combine the files"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b3LvQcX893e-"
      },
      "outputs": [],
      "source": [
        "data_cs = pd.concat(files_cs.values(), ignore_index=True) # combine \"files_cs\" into a pandas dataframe\n",
        "              # reset index with drop = True (ignore_index = True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v6HmuK0a93e_"
      },
      "source": [
        "## Prepare Final Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "To_iaXYD93e_"
      },
      "outputs": [],
      "source": [
        "# Keep only the columns of interest from 'data_cs'\n",
        "final_data = data_cs[cols_to_pick]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_LZg1AFW93e_",
        "outputId": "42d892c1-02b9-410c-bbc6-68521eb745fe"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Starting with 2777776 rows\n"
          ]
        }
      ],
      "source": [
        "print(\"Starting with \" + str(len(final_data)) + \" rows\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wr-sjAWw93e_"
      },
      "source": [
        "### Typecast the columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "032Yasls93e_",
        "outputId": "f8e539f5-b2e3-4c92-8183-75d0e995fa31"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\strik\\AppData\\Local\\Temp\\ipykernel_28960\\1286980223.py:5: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  final_data[i] = final_data[i].astype(float) # typecast float columns\n"
          ]
        }
      ],
      "source": [
        "# Remember that we read the data as string (without any formatting).\n",
        "# Now we would typecast the columns based on feature types which you found out in CS Phase 1\n",
        "\n",
        "for i in float_cols:\n",
        "    final_data[i] = final_data[i].astype(float) # typecast float columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q99NSQbh93e_",
        "outputId": "145eea54-561d-4a57-aa55-3b20d54efbda"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\strik\\AppData\\Local\\Temp\\ipykernel_28960\\255568752.py:8: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  final_data[i] = final_data[i].apply(clean_perc) # apply clean_perc to percentage columns\n"
          ]
        }
      ],
      "source": [
        "def clean_perc(x):\n",
        "    if pd.isnull(x):\n",
        "        return np.nan\n",
        "    else:\n",
        "        return float(x.strip()[:-1])\n",
        "\n",
        "for i in perc_cols:\n",
        "    final_data[i] = final_data[i].apply(clean_perc) # apply clean_perc to percentage columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uHCc86Wh93fA",
        "outputId": "00b5201a-0a38-4ced-c8e4-0af7604d2c49"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\strik\\AppData\\Local\\Temp\\ipykernel_28960\\2653851960.py:8: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  final_data[i] = final_data[i].apply(clean_date) # typecast date cloumns to datatime using clean_date\n"
          ]
        }
      ],
      "source": [
        "def clean_date(x):\n",
        "    if pd.isnull(x):\n",
        "        return None\n",
        "    else:\n",
        "        return datetime.datetime.strptime( x, \"%b-%Y\").date()\n",
        "\n",
        "for i in date_cols:\n",
        "    final_data[i] = final_data[i].apply(clean_date) # typecast date cloumns to datatime using clean_date"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "HyzrAUFY93fA",
        "outputId": "d0e5ef7a-08f5-47fd-9c77-24dc1152eedc"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\strik\\AppData\\Local\\Temp\\ipykernel_28960\\2666031082.py:2: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  final_data[i] = final_data[i].fillna('None') # for categorical features if the value is null/empty set it to None\n"
          ]
        }
      ],
      "source": [
        "for i in cat_cols:\n",
        "    final_data[i] = final_data[i].fillna('None') # for categorical features if the value is null/empty set it to None"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JRkozSGA93fA"
      },
      "source": [
        "## Calculate returns for each loan"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O_Caw7P893fA"
      },
      "outputs": [],
      "source": [
        "# Define the names of the four returns we'll be calculating as described in Q.6\n",
        "# ret_PESS: Pessimistic return\n",
        "# ret_OPT: Optimistic return\n",
        "# ret_INTa, ret_INTb: Method3 at two differnt values of \"i\"\n",
        "ret_cols = [\"ret_PESS\", \"ret_OPT\", \"ret_INTa\", \"ret_INTb\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KlPlkUIC93fA",
        "outputId": "57fb0cb8-dd73-46c3-eccd-987f1df4f1bb"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\strik\\AppData\\Local\\Temp\\ipykernel_28960\\2265092521.py:2: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  final_data['loan_length'] = (final_data.last_pymnt_d - final_data.issue_d) / np.timedelta64(1, 'M')\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Removed 12361 rows\n"
          ]
        }
      ],
      "source": [
        "# Remove all rows for loans that were paid back on the days they were issued\n",
        "final_data['loan_length'] = (final_data.last_pymnt_d - final_data.issue_d) / np.timedelta64(1, 'M')\n",
        "n_rows = len(final_data)\n",
        "\n",
        "final_data = final_data[final_data['loan_length'] != 0] # select rows where loan_length is not 0.\n",
        "\n",
        "print(\"Removed \" + str(n_rows - len(final_data)) + \" rows\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HfufDyLL93fA"
      },
      "source": [
        "### M1-Pessimistic Method"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "final_data.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 166
        },
        "id": "SyHsuAOI7n_f",
        "outputId": "ac253dc9-f298-447f-f35b-73533b8eb8e5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-a62255032a45>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mfinal_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'final_data' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "id": "wYm8pwe693fB",
        "outputId": "0be66135-d347-4bec-adf2-7da35ade96fa"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-50a3554df117>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# Pessimistic definition (Handout 6a.) (M1)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mfinal_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'term_num'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfinal_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mterm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextract\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'(\\d+)'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mexpand\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# length of loan in months\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mfinal_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'ret_PESS'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m...\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'final_data' is not defined"
          ]
        }
      ],
      "source": [
        "# Calculate the return using a simple annualized profit margin\n",
        "# Pessimistic definition (Handout 6a.) (M1)\n",
        "\n",
        "final_data['term_num'] = final_data.term.str.extract('(\\d+)',expand=False).astype(int) # length of loan in months\n",
        "\n",
        "final_data['ret_PESS'] = ..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zpaPKtzQ93fB"
      },
      "source": [
        "### M2-Optimistic Method"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('test')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X9b3wtqE7bd7",
        "outputId": "de11e1d1-b411-464d-99dd-b841728b3765"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "test\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "id": "OfIfKiNg93fB",
        "outputId": "4f3d379e-a419-498e-f3b9-af63015c4a0c"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-c610fc6df3cd>\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# takes a loss, we use M1-pessimistic to compute the return\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mfinal_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'ret_OPT'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m...\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mfinal_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfinal_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mret_OPT\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'ret_OPT'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m...\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'final_data' is not defined"
          ]
        }
      ],
      "source": [
        "# Assuming that if a loan gives a positive return, we can\n",
        "# immediately find a similar loan to invest in; if the loan\n",
        "# takes a loss, we use M1-pessimistic to compute the return\n",
        "\n",
        "final_data['ret_OPT'] = ...\n",
        "\n",
        "final_data.loc[final_data.ret_OPT < 0,'ret_OPT'] = ..."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "IxtnDArQ7aQ0"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xfCoIKT993fB"
      },
      "source": [
        "### Method 3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "5a3hOCUV93fB"
      },
      "outputs": [],
      "source": [
        "def ret_method_3(T, i):\n",
        "    '''\n",
        "    Given an investment time horizon (in months) and re-investment\n",
        "    interest rate, calculate the return of each loan\n",
        "    '''\n",
        "\n",
        "    # Assuming that the total amount paid back was paid at equal\n",
        "    # intervals during the duration of the loan, calculate the\n",
        "    # size of each of these installment\n",
        "    actual_installment = (final_data.total_pymnt - final_data.recoveries) / ...\n",
        "\n",
        "    # Assuming the amount is immediately re-invested at the prime\n",
        "    # rate, find the total amount of money we'll have by the end\n",
        "    # of the loan\n",
        "    cash_by_end_of_loan = actual_installment * ... # compute the quantity given in [] in eq.2.3 of handout\n",
        "\n",
        "    cash_by_end_of_loan = cash_by_end_of_loan + final_data.recoveries\n",
        "\n",
        "    # Assuming that cash is then re-invested at the prime rate,\n",
        "    # with monthly re-investment, until T months from the start\n",
        "    # of the loan\n",
        "    remaining_months = T - final_data['loan_length']\n",
        "    final_return = cash_by_end_of_loan * ...\n",
        "\n",
        "    # Find the percentage return\n",
        "    ret_val = (12/T) * ...\n",
        "    return ret_val"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "5VqtCCOl93fB"
      },
      "outputs": [],
      "source": [
        "final_data['ret_INTa'] = ... # call ret_method_3 with T=60, i=0.023\n",
        "final_data['ret_INTb'] = ... # call ret_method_3 with T=60, i=0.04"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lccemb2z93fB"
      },
      "source": [
        "### Visualize the variables"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "aRPxUy7r93fB"
      },
      "outputs": [],
      "source": [
        "def visualize_float_columns():\n",
        "    '''\n",
        "    This function visualizes Box-and-whisker plots for continuous variables\n",
        "    '''\n",
        "\n",
        "    # FLoat columns\n",
        "    for i in float_cols + perc_cols + ret_cols:\n",
        "        seaborn.boxplot(final_data[i])\n",
        "\n",
        "        # Print the three highest values\n",
        "        highest_vals = ... # get 3 highest values\n",
        "\n",
        "        smallest_val = min(final_data[i])\n",
        "\n",
        "        plt.text(smallest_val, -0.3, highest_vals[0])\n",
        "        plt.text(smallest_val, -0.2, highest_vals[1])\n",
        "        plt.text(smallest_val, -0.1, highest_vals[2])\n",
        "\n",
        "        plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "i9DUz5HV93fB"
      },
      "outputs": [],
      "source": [
        "def visualize_cat_columns():\n",
        "    '''\n",
        "    Lists the distinct values for categorical columns\n",
        "    '''\n",
        "    # Categorical columns\n",
        "    for i in cat_cols:\n",
        "        ... # print field name\n",
        "        ... # print number of distinct values\n",
        "        ... # for each distinct value print the number of occurances\n",
        "        print(\"\")\n",
        "        print(\"\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "jQgOoMBV93fB"
      },
      "outputs": [],
      "source": [
        "def visualize_date_columns():\n",
        "    '''\n",
        "    This function visualizes a timeline density for dates\n",
        "    '''\n",
        "\n",
        "    # Date columns\n",
        "    for i in date_cols:\n",
        "        final_data[final_data[i].isnull() == False][i].apply(lambda x : str(x.year) +\n",
        "                                                \"-\" + str(x.month)).value_counts(ascending = True).plot()\n",
        "        plt.title(i + \" (\" + str(final_data[i].isnull().sum()) + \" null values)\")\n",
        "        plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "kagd_vje93fC"
      },
      "outputs": [],
      "source": [
        "# visualize continuous features\n",
        "...\n",
        "\n",
        "# visulaize categorical features\n",
        "...\n",
        "\n",
        "# visualize date columns\n",
        "..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hGUTAwcZ93fC"
      },
      "source": [
        "### Handle outliers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "nMlpmlTe93fC"
      },
      "outputs": [],
      "source": [
        "# There are quite a few outliers.\n",
        "# Please identify top-k (decide this based on the visualization) features where outliers are most obvious\n",
        "n_rows = len(final_data)\n",
        "\n",
        "final_data = ... # remove outliers based 1st obvious feature\n",
        "final_data = ... # remove outliers based 2nd obvious feature\n",
        "...\n",
        "final_data = ... # remove outliers based kth obvious feature\n",
        "\n",
        "print(\"Removed \" + str(n_rows - len(final_data)) + \" rows\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "3ImcyRwm93fC"
      },
      "outputs": [],
      "source": [
        "# Remove all loans that are still current\n",
        "n_rows = len(final_data)\n",
        "\n",
        "final_data = ...\n",
        "\n",
        "print(\"Removed \" + str(n_rows - len(final_data)) + \" rows\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "_92nJKQO93fC"
      },
      "outputs": [],
      "source": [
        "# Only include loans isssued since 2010\n",
        "n_rows = len(final_data)\n",
        "\n",
        "final_data = ...\n",
        "\n",
        "print(\"Removed \" + str(n_rows - len(final_data)) + \" rows\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-gpyS4-c93fC"
      },
      "source": [
        "### Drop null values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "WQnwKyHD93fC"
      },
      "outputs": [],
      "source": [
        "# Deal with null values. We allow cateogrical variables to be null\n",
        "# OTHER than grade, which is a particularly important categorical.\n",
        "# All non-categorical variables must be non-null, and we drop\n",
        "# rows that do not meet this requirement\n",
        "\n",
        "required_cols = set(cols_to_pick) - set(cat_cols) - set([\"id\"])\n",
        "required_cols.add(\"grade\")\n",
        "\n",
        "n_rows = len(final_data)\n",
        "\n",
        "... # drop rows that contain null based only on \"required_cols\"\n",
        "\n",
        "print(\"Removed \" + str(n_rows - len(final_data)) + \" rows\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SFelGRtL93fD"
      },
      "source": [
        "### Visualize clean data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "aJ0zG_2I93fD"
      },
      "outputs": [],
      "source": [
        "# Visualize the data again after cleaning\n",
        "...\n",
        "...\n",
        "..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "IBEKCAhT93fD"
      },
      "outputs": [],
      "source": [
        "# Visualize the feature correlations\n",
        "    # You can compute the correlation among features and display a heat-map of the matrix\n",
        "    # OR use sns scatter or pairplot\n",
        "...\n",
        "..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "KJJ_Fr-393fD"
      },
      "outputs": [],
      "source": [
        "# Visualize relation between loan status and features\n",
        "... # sns pairplot or scatter plot. Refer to recitations\n",
        "...\n",
        "..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m0A6v7PO93fD"
      },
      "source": [
        "What do you observe after removing the outliers?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z3J_bDNF93fD"
      },
      "source": [
        "### Data Exploration\n",
        "Solution to Q.7 from the handout"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "hfgkhS5g93fD"
      },
      "outputs": [],
      "source": [
        "# Find the percentage of loans by grade, the default by grade,\n",
        "# and the return of each grade\n",
        "perc_by_grade = (final_data.grade.value_counts()*100/len(final_data)).sort_index()\n",
        "\n",
        "default_by_grade = final_data.groupby(\"grade\").apply(lambda x : (x.loan_status != \"Fully Paid\").sum()*100/len(x) )\n",
        "ret_by_grade_OPT = ... # average return for M2-Optimistic for each loan grade\n",
        "ret_by_grade_PESS = ... # average return for M1-Pessimistic for each loan grade\n",
        "ret_by_grade_INTa = ... # average return for M3\n",
        "ret_by_grade_INTb = ... # average return for M3\n",
        "int_rate_by_grade = ... # average interest rate for each grade\n",
        "\n",
        "combined = pd.DataFrame(perc_by_grade)\n",
        "combined.columns = ['perc_of_loans']\n",
        "combined['perc_default'] = default_by_grade\n",
        "combined['avg_int_rate'] = int_rate_by_grade\n",
        "combined['return_OPT'] = ret_by_grade_OPT\n",
        "combined['return_PESS'] = ret_by_grade_PESS\n",
        "combined['return_INTa'] = ret_by_grade_INTa\n",
        "combined['return_INTb'] = ret_by_grade_INTb\n",
        "\n",
        "combined"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VX1rke_c93fD"
      },
      "source": [
        "Based on the output of previous cell, write down your answers to Q.7 from the handout."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dTz6-XC193fD"
      },
      "source": [
        "### Save a Pickle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "HusJ8OcJ93fD"
      },
      "outputs": [],
      "source": [
        "# Remove the \"total_pymnt\" and \"recoveries\" from the list of continuous features\n",
        "continuous_features = ..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lu4_5eb293fD"
      },
      "source": [
        "Why did we remove `total_pymt` and `recoveries` from the data for the task of predicting whether to give loan or not, although these are highly predictive features?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "koLWN7UX93fD"
      },
      "outputs": [],
      "source": [
        "# save the prepared data for modeling in next Phase.\n",
        "pickle.dump( [final_data, discrete_features, continuous_features, ret_cols], open(pickle_file, \"wb\") )"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.10"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}